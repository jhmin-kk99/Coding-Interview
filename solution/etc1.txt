Pipeline이란?

단일사이클은 설계가 올바르게 작동한다 하더라도 비효율성 때문에 현대적 설계에서는 쓰이지 않는다.
단일사이클 설계에서는 클럭 사이클이 모든 명령어에 대해 같은 길이를 가져야 하기 때문이다. 클럭 사이클은
컴퓨터에서 가능한 경로 중 가장 긴 경로에 의해 결정된다. 이 최장 경로는 lw명령어라는 것이 거의 확실
한데, 이 적재 명령어는 명령어 메모리, 레지스터 파일, ALU, 데이터 메모리, 레지스터 파일의 다섯 개 기능
유닛을 차례로 사용한다. CPI값은 1이지만, 단일 사이클 구현은 클럭 사이클이 너무 길기 때문에 전체 성능
은 좋지 않다. 

파이프라이닝(pipelining)은 여러 명령어가 중첩되어 실행되는 구현 기술이다. 

파이프라이닝은 다음의 특성을 지닌다.
- piplelining doesn't help latency of single task, it helps throughput of entire workload
- pipeline rate limited by slowest pipeline stage
- multiple tasks operating simultaneously using different resources
- potential speedup = number pipe stages
- unbalanced lengths of pipe stages reduces speedup
- time to 'fill' pipeline and time to 'drain' it reduces speedup
- stall for dependences

MIPS pipeline은 명령어 처리에 5단계를 거친다
1. IF : Instruction fetch from memory(Ifetch)
2. ID : Instruction decode & register read(ID/Reg)
3. EX : Execute operation or calculate address(Exec)
4. MEM : Access memory operand(Mem)
5. WB : Write result back to register(Wr)

why pipeline?

suppose
- 100 instructions are executed
- the single cycle machine has a cycle time of 45ns
- the multicycle and pipeline machines have cycle times of 10ns
- the multicycle machine has a CPI of 3.6

# single cycle machine
45 ns/cycle * 1 CPI * 100 inst = 4500 ns
# multicycle machine
10 ns/cycle * 3.6 CPI * 100 inst = 3600 ns
# ideal pipelined machine
10 ns/cycle * (1 CPI * 100 inst + 4 cycle drain) = 1040 ns
# ideal pipelined vs single cycle speedup
4500 ns / 1040 ns = 4.33


명령어의 5단계 각각을 수행하는 동안, 각 명령어의 값, 레지스터의 값 등을 유지하기 위해서 해당 단계에서 
사용중인 값을 레지스터에 저장해야 한다. 이를 'Pipeline Register'라고 한다.

다음 명령어가 다음 클럭 사이클에 실행될 수 없는 상황이 있다. 이러한 사건을 해저드(hazard)라 부르는데 세 종류가 있다.

# structural hazards(구조적 해저드) : attempt to use the same resource two different ways at the same time
- Eg. two instructions try to read the same memory at the same time
구조적 해저드는 클럭 사이클에 실행하기를 원하는 여러 명령어들의 수행을 하드웨어가 지원할 수 없기 때문에 발생한다. 
각 파이프라인의 단계는 자신이 맡은 동작을 실행하기 위해서 메모리나 레지스터 등의 구성 요소를 사용하게 되는데, 
같은 파이프라인 단계에 있는 명렁어들이 동시에 하나의 자원을 같이 사용하려고 하면 파이프라인이 지연될 수 있다. 
파이프라인을 설계할 때 구조적 해저드를 피하도록 유의해야한다.

solution 1 : Instruction fetch would have to stall for that
- would cause a pipeline 'bubble'
solution 2 : pipelined datapaths require separate instruction/data memories
- or separate instruction/data caches
solution 3 : allow memory to read and write more than one word per cycle 
- 2 read, 1 write port가 있는 register file 처럼

# data hazards(데이터 해저드) : attempt to use item before it is ready
- instruction depends on result of prior instruction still in the pipeline
add r1, r2, r3
sub r4, r2, r1

solution 1 : insert the stalls(nops)
- this really slows us down
solution 2 : Internal bypassing, Data forwarding
Internal bypassing
- fix register file access hazard by doing reads in the second half of the cycle and writes in the first half
register file의 Read Address1 혹은 Read Address2와 Write Address가 같으면, Write Data를 Read Data1 혹은 Read Data2에 보내준다.
Data forwarding
- Use temporary results, don't wait for them to be written 

1. 
add r1,r2,r3
sub r1,r1,r5
and r6,r7,r1
or r8,r1,r1
sw r4,100(r1)
data forwarding으로 해결 가능
- can fix data hazard by forwarding results as soon as they are available to where they are needed)
2.
add $1,$1,$2
add $1,$1,$3
add $1,$1,$4
another potential data hazard can occur
- when there is a conflict between the result of the WB stage instruction and the MEM stage instruction
- which should be forwarded? More recent result!
3.
lw $2,20($1)
and $4,$2,$5
can't always avoid stalls by forwarding
- if value not computed when needed
- can't forward backward in time!
must delay/stall instruction dependent on loads

# control hazards(제어 해저드) : attempt to make a decision before condition is evaluated
- branch instructions
beq r1, r4, loop
add r1, r2, r3

branch determines flow of control
- conditional branches (beq, bne)
- unconditional branches (j)
when the flow of instruction addresses is not sequential; incurred by change of instructions(Branch)
- fetching next instruction depends on branch outcome
- pipeline can't always fetch correct instruction

solution1 : stall
- wait until decision is clear
j incur 1 stall
jumps not decoded until ID, so one flush is needed (pc+4)

solution2 : reducing branch delay 
move decision point earlier in the pipeline(from to ID stage)
1. move the branch decision hardware back to the EX stage
- reduces the number of stall (flush) cycles to two
- adds an and gate and a 2x1 mux to the EX timing path

2. add hardware to compute the branch target address and evaluate the branch decision to the ID stage
- reduces the number of stall (flush) cycles to one (like with jumps)
(but now need to add forwarding hardware in ID stage)
- computing branch target address can be done in parellel with RegFile read
(done for all instructions - only used when needed)
- comparing the registers can't be done until after RegFile read, so comparing and updating the PC adds
a mux, a comparator, and an and gate to the ID timing path

3. For deeper pipelines, branch decision points can be even later in the pipeline, incurring more stalls

solution3 : predict
longer pipelines can't readily determine branch outcome early
- stall penalty becomes unacceptable
predict outcome of branch
-only stall if prediction is wrong
in MPIS pipeline
- can predict branches not taken
- fetch instruction after branch, with no delay
- back up if wrong
(Impact : 1 clock cycle per branch instruction if right, 2 cycles if wrong)

More-Realistic Branch Prediction

Static branch prediction(정적 분기 예측)
Based on typical branch behavior
Example : loop and if-statement branches
- predict backward branches taken (Loop을 많이 돌 것으로 예측)
- predict forward branches not taken

Dynamic branch prediction(동적 분기 예측)
Hardware measures actual branch behavior
- e.g. record recent history of each branch
Assume future behavior wil continue the trend
- When wrong, stall while re-fetching, and update history

solution4 : delay decision (requires compiler support)
control hazards occur less frequently than data hazards
- there is nothing as effective against control hazards as forwarding is for data hazards

Unexpected Events in Pipeline

Exception(예외자) : Arises within the CPU
- e.g. undefined opcode, overflow, syscall ...
Interrupt : From an external I/O controller

"Unexpected" events requiring change in flow of control
(정상적으로 진행하다가 서비스루틴을 실행하기 때문에 control flow가 변경됨)
- Different ISAs use the terms differently

Dealing with them without sacrificing performance is hard

Two types of Exceptions

# Interrupts - asynchronous(비동기) to program execution
- caused by external events (별도의 이벤트, 파이프라인 계산 결과에 영향x)
- may be handled between instructions, so can let the instructions currently active in the pipeline complete
before passing control to the OS interrupt handler
- simply suspend and resume user program
새로운 명령어를 가져오는 것이 아니라 멈추고 서비스루틴에 들어간 후 끝나면 실행함

# Traps(Exception) - synchronous(동기) to program execution
- caused by internal events
- condition must be remedied by the trap handler for that instruction, so much stop the offending instruction
midstream in the pipeline and pass control to the OS trap handler (cache miss, pagefault ...)
- the offending instruction may be retried (or simulated by the OS) and the program may continue or it may be 
aborted

동기 : 동시에 일어난다는 뜻. 요청과 그 결과가 동시에 일어남. 바로 요청을 하면 시간이 얼마나 걸리던지 요청한 자리에서
결과가 주어져야함
설계가 매우 간단하고 직관적이지만, 결과가 주어질 때까지 아무것도 못하고 대기해야함

비동기 : 요청과 결과가 동시에 일어나지 않음
동기보다 복잡하지만, 결과가 주어지는데 시간이 걸리더라도 그 시간동안 다른 작업을 할 수 있으므로 자원을 효율적으로 사용가능

Exceptions are just another form of control hazard
Exceptions arise from
- R-type arithmetic overflow (stage : EX / synchronous)
- Trying to execute an undefined instruction (stage : ID / synchronous)
- An I/O device request (stages : IF, MEM / synchronous)
- An OS service request (e.g. a page fault, TLB exception) (stages : any / asynchronous)
- A hardware malfunction (stages : any / asynchronous)

The pipeline must stop executing the offending instruction in midstream
- let all prior instructions(상관없음) complete,
- flush all following instructions,
- set a register to show the cause of the exception,
- save the address of the offending instruction,
- and then jump to a prearranged address (the address of the exception handler code) (service routine 실행)
The software (OS) looks at the cause of the exception and "deals" with it

Handling Exceptions
In MIPS, exceptions managed by System Control Coprocessor(CP0)
Save PC of offending (or interrupted) instruction
- In MIPS : Exception Program Counter(EPC)
(offending instruction의 return address를 가져오기 위해(PC+4))
Save Indication of the problem
- In MIPS : Cause register
Jump to a service handler

Vectored Interrupts
- Handler address determined by the cause
Example :
- Undefined opcode : C000 0000
- Overflow : C000 0020
- ...
Instructions either
- Deal with the interrupt, or
- Jump to real handler

Handler Actions
Read cause, and transfer to relevent handler
Determine action required
If restartable (Pipeline can flush the instruction)
- Take corrective action 
- use EPC to return to program (Refetched and executed from scratch (처음부터 다시 시작))
PC saved in EPC register : 
- Identifies causing instruction
- Actually PC+4 is saved (Handler must adjust)

Otherwise(undefined instruction, hardware malfunction ...)
- Terminate program
- Report error using EPC, cause, ...

Consider overflow on add in EX stage
add $1, $2, $1
- Prevent $1 from being clobbered
- Complete previous instructions
- Flush add and subsequent instructions
- Set Cause and EPC register values
- Transfer control to handler

Additions to MIPS to Handle Exceptions
Cause register(records exceptions) 
- hardware to record in Cause the exceptions and a signal to control writes to it
(CauseWrite)
EPC register(records the addresses of the offending instructions) 
- hardware to record in EPC the address of the offending instruction and a signal to control writes to it
(EPCWrite)
A way to load the PC with the address of the exception handler
- Expand the PC input mux where the new input is hardwired to the exception handler address
-(e.g. 8000 0180hex for arithmetic overflow)
A way to flush offending instruction and the ones that follow it

Pipelining overlaps multiple instructions
- Could have multiple exceptions at once
Simple approach : deal with exception from earliest instruction
- Flush subsequent instructions
- "Precise" exceptions (Modern processors)
In complex pipelines
- Multiple instructions issued per cycle
- Out-of-order completion
- Maintaining precise exceptions is difficult!

Imprecise Exceptions
Just stop pipeline and save state
- Including exception cause(s)
Let the handler work out
- which instruction(s) had exceptions
- which to complete or flush
(may require "manual" completion)
Simplifies hardware, but more complex handler software
Not feasible for complex multiple-issue
out-of-order pipelines

Instruction-Level Parallelism (ILP) 에서 더 병렬도를 높이는 방법

# Deeper pipeline
- Less work per stage (shorter clock cycle)
세탁소 비유에서, 세탁기 사이클이 다른 것들에 비해 길다면, 세탁기를 3개의 기계로 나눌 수 있다.
한 기계가 하던 세탁, 헹굼, 탈수의 3단계를 각각 다른 기계로 나눌 수 있다. 그렇게 하면 4단계 파이프라인에서 
6단계 파이프라인으로 바뀐다. 최고 성능을 얻기 위해서는 나머지 단계들을 다시 균형을 잡아서 단계들이 같은 길이를 갖도록 할 필요가 있다.
더 많은 연산들이 중첩되기 때문에 추구되는 병렬성의 양은 늘어나고, 클럭 사이클이 더 짧아질 것이기 때문에 성능이 더 좋아질 가능성이 있다.

# Multiple issue
매 파이프라인 단계에서 다수의 명령어를 내보낼 수 있도록 하는것
- Replicate pipeline stages (multiple pipelines)
- Start multiple instructions per clock cycle
- CPI < 1, so use Instructions Per Cycle (IPC)
pipeline에서 이상적인 CPI는 1이다. 매 단계마다 다수의 명령어를 내보내면 CPI가 1보다 작아질 수 있다.
CPI값이 1보다 작아지면 측도를 뒤집어서 IPC 를 사용하기도 한다.
- E.g. 4GHZ 4-way multiple-issue 
(16 BIPS, peak CPI = 0.25, peak IPC = 4)
- But dependencies reduce this in practice

# Static muiltiple issue (컴파일 시에, 정적으로)
- Compiler groups instructions to be issued together
- Packages them into "issue slots"
- Compiler detects and avoids hazards
static multiple issue에서 같은 클럭 사이클에 내보내지는 명령어의 묶음(issue packet)을 여러 개의 연산자를 갖는
큰 명령어 하나로 생각할 수 있다. 일반적으로 주어진 클럭 사이클에 같이 나갈 수 있는 명령어 조합에 제한이 있기 때문에,
issue packet을 미리 정의된 필드에 여러 연산자가 있는 단일 명령어로 보는 것이 유용하다.
Compiler groups instructions into "issue packets"
- Group of instructions that can be issued on a single cycle
- Determined by pipeline resources required

Issue slots : 주어진 clock cycle에서 명령어들이 내보내질 수 있는 위치. 
비유를 들자면 단거리 선수를 위한 출발선 블록의 위치와 같다.
Issue packets : 1 clock cycle에 같이 내보내지는 명령어들의 집합. 패킷은 컴파일러에 의해 정적으로 
결정될 수도 있고 프로세서에 의해 동적으로 결정될 수도 있다.

Think of issue packet as a very long instruction
- Specifies multiple concurrent operations
-> Very Long Instruction Word (VLIW)

Scheduling Static Multiple Issue
Compiler must remove some/all hazards
- Reorder instructions into issue packets
- No dependencies with a packet
- Possibly some dependencies between packets
(Varies between ISAs; compiler must know)
- Pad with nop if necessary

Two-issue packets
One ALU/branch instruction
One load/store instruction
64-bit aligned
- ALU/branch, then load/store
- Pad an unused instruction with nop

Hazards in the Dual-Issue MIPS
More instructions executing in parallel
EX data hazard
- Forwarding avoided stalls with single-issue
- Now can't use ALU result in load/store in same packet
add $t0, $s0, $s1
load $s2, 0($t0)
(split into two packets, effectively a stall)
Load-use hazard
- Still one cycle use latency, but now two instructions
More aggressive scheduling required

Loop Unrolling 
Replicate loop body to expose more parallelism
- Reduces loop-control overhead
Use different registers per replication
- Called "register renaming"
목적은 진정한 데이터 종속성은 아니지만 잠재적 해저드의 원인이 되거나 컴파일러가 유연하게 스케줄
하는 것을 방해하는 종속성을 없애자는 것이다.
- Avoid loop-carried "anti-dependencies(반종속성)"(또는 "name dependence"(이름 종속성))
실제로 데이터 종속성이라기보다 순전히 하나의 이름을 계속 사용함으로써 강요되는 순서

# Dynamic multiple issue (실행 중에, 동적으로)
- CPU examines instruction stream and chooses instructions to issue each cycle
- Compiler can help by reordering instructions
- CPU resolves hazards using advanced techniques at runtime

"Superscalar"(프로세서가 실행 중에 명령어를 선택하여 한 클럭 사이클에 두 개 이상의 명령어를 실행할 수 
있도록 해 주는 고급 파이프라이닝 기법) processors
CPU decides whether to issue 0,1,2,... each cycle
- Avoiding structural and data hazards
Avoids the need for compiler scheduling
- Though it may sill help
- Code semantics ensured by the CPU
많은 수퍼스칼라 프로세서는 dynamic multiple issue를 결정하는 기본 틀을 확장하여 dynamic pipeline scheduling을
포함하도록 한다. 이 동적 파이프라인 스케줄링은 해저드와 지연은 피하면서 주어진 클럭 사이클에 어떤 명령어를 실행할
것인지 선택한다.

Dynamic Pipeline Scheduling
Allow the CPU to execute instructions out of order to avoid stalls
- But commit result to registers in order
Example
lw $t0, 20($s2)
addu $t1, $t0, $t2
sub $s4, $s4, $t3
slti $t5, $s4, 20
Can start sub while addu is waiting for lw

이러한 프로세서에서 파이프라인은 세개의 주요 유닛으로 나누어짐 
1. Instruction fetch and decode unit (In-order issue, for preserving dependencies)
명령어를 인출하고 해독하고 각각의 명령어를 실행 단계의 해당 Functional unit에 보냄 
2. Functional units (Out-of order execute)
각 Funtional unit은 reservation station(대기영역)(Hold pending operands)이라 불리는 버퍼를 가지고 있는데 
이 reservation station은 피연산자와 연산자를 가지고 있다. 필요한 모든 피연산자가 버퍼에 준비되고 실행할 
functional unit이 준비가 되어 있으면(dependency가 해결이 되면) 결과가 계산된다.
(다른 파이프라인에서 결과를 만들고 있으면 준비x) 결과가 완료되면 이 결과는 Commit unit뿐만 아니라 이 특정한 
결과를 기다리고있는 reservation station에 보내진다.(Results also sent to any waiting reservation stations)
3. Commit unit (In-order commit)
결과값을 버퍼에 두었다가 안전하다고 생각이 들 때 결과값을 레지스터 파일이나 메모리(sw의 경우)에 명령어 순서대로 쓴다.
Commit unit에 있는 이 버퍼는 reorder buffer(재정렬 버퍼)라고 불리는데 피연산자들을 제공하는 데 사용된다.
일단 결과값이 레지스터 파일에 써지면 정상적인 파이프라인에서와 같이 레지스터 파일로부터 직접 읽을 수 있다.

Register Renaming
Reservation stations and reorder buffer effectively provide register renaming
1. 명령어가 내보내질 때(instruction issue to reservation station) 명령어는 해당 functional unit의 
reservation station으로 복사된다. 피연산자 중에 레지스터 파일이나 reorder buffer에 있는 것이 있으면 
이 피연산자는 즉시 reservation station으로 복사된다. 명령어는 모든 피연산자와 실행 유닛이 사용 가능할 때까지 버퍼링된다. 
내보내지는 명령어의 피연산자는 레지스터값이 더 이상 필요 없으며, 이 레지스터에 쓰기가 일어난다면 그냥 덮어써도 문제가 없다.(이미 복사해왔기 때문)
2. 만약 피연산자가 레지스터 파일이나 reorder buffer에 없다면 functional unit에 의해 생성될 때까지 기다려야한다.
결과를 만들어 낼 functional unit의 이름이 추적된다. 그 functional unit이 결국 결과를 만들면 functional unit에서 기다리고 
있는 reservation station으로 직접 복사된다. 이 때, Register update may not be required (commit unit에서 함)

# 성능 향상 방법 : Speculation (추정)
예측이라는 개념을 기반으로 하여 추정은 컴파일러나 프로세서가 명령어의 특성에 대해 추측하도록
허락하여 이 명령어에 종속적일 수 있는 다른 명령어들의 실행을 시작할 수 있게 하는 방법이다. 
- e.g. branch 명령어의 결과를 추정한다면 branch 뒤의 명령어들이 일찍 실행될 수 있다. 
- e.g. lw 명령어 바로 앞의 sw 명령어가 같은 주소를 참조하지 않는다고 추정하여, lw 명령어가
sw 명령어보다 먼저 실행될 수 있게 하는 것이다.
Start operation as soon as possible
Check whether guess was right
- if so, complete the operation
- if not, roll-back and do the right thing
어떠한 추정 기법도 추정이 올바른지를 체크할 방법과 추정해서 실행했던 명령어들을 되돌리거나 아니면
그 효과를 취소하는 방법을 포함하여야 한다. 이 같은 취소 능력에 대한 구현은 추정을 지원하는 프로세서가 더 높은 복잡도를 가지게 한다.

Compiler can reorder instructions
E.g. speculation to reorder an instruction across branch or load across store instruction.
Can include "fix-up" instructions to recover from incorrect guess
컴파일러는 추정의 정확성을 체크할 명령어들을 추가하고 추정이 잘못되었을 때 사용 할 오류 수정 루틴을 제공한다.

Hardware can look ahead for instructions to execute
Buffer results until they are determined and then actually needed
Flush buffers on incorrect speculation
하드웨어 추정인 경우 프로세서는 추정 결과가 더이상 추정이 아니라는 걸 알 때까지 추정 결과를 버퍼링하는 것이 보통이다. 
추정이 옳다면 버퍼의 내용을 레지스터나 메모리에 씀으로써 명령어 실행이 완성된다. 만약 추정이 틀렸으면 
하드웨어는 버퍼내용을 쓸어버리고 올바른 명령어 순서를 다시 실행한다.

What if exception occurs on a speculatively executed instruction?
e.g. speculative load before null-pointer-check

Static speculation(컴파일러 기반의 추정)
- can add ISA support for deferring exceptions
(예외가 정말 일어나야 한다는 사실이 확실해질 때까지 무시할 수 있게 해 주는 ISA support를 추가한다.)
Dynamic speculation(하드웨어 기반의 추정)
- can buffer exceptions until instruction completion(which may not occur)
(예외를 버퍼링해 두었다가, 예외를 일으킨 명령어가 추정 상태에서 벗어나 실행완료할 준비가 되면 이때 예외를
일으키고 정상적인 예외처리를 진행한다.)
Dynamic Pipeline Scheduling은 흔히 하드웨어 기반의 추정을 포함하도록 확장된다. 
Predict branch and continue issuing
특히 branch의 결과에 대해서는 더욱 그러하다. branch의 방향을 예측함으로써 dynamin pipeline scheduling은 예측한
경로를 따라 명령어 인출과 실행을 계속할 수 있다. 명령어들은 순서대로 결과를 쓰기 때문에, 예측한 경로상의 명령어가 
결과를 쓰기 전에 branch prediction의 정확성 여부를 판단할 수 있다.  
Load speculation( lw 명령어 바로 앞의 sw 명령어가 같은 주소를 참조하지 않는다고 추정)
- Avoid load and cache miss delay
1. Predict the effective address
2. Predict loaded value
3. Load before completing outstanding stores
4. Bypass stored values to load unit
- Don't commit load until speculation cleared

추정이 올바르게 이루어지면 성능이 향상되고 추정이 잘못되면 성능이 감소하기 때문에 추정을 언제 하는 것이 좋은지
결정하는 데 막대한 노력을 기울여야 한다. 

Why Do Dynamic Scheduling?

컴파일러가 데이터 종속성이 있는 명령어들 주변의 코드를 스케줄할 수 있다면 왜 수퍼스칼라 프로세서는 dynamic scheduling을 할까? 
1. Not all stalls are predictable (e.g. cache misses)
a($10), b($10), a($11) 은 모두 같은 주소를 나타낼 수도 있고, 다른 주소를 나타낼 수도 있다. 
컴파일러는 이것을 예측하거나 판단할 수 없음. run time에서만 알 수 있다.
메모리 계층구조에서 cache misses는 예측 불가능한 지연을 일으킨다. dynamic scheduling은 프로세서로 하여금 지연이 
끝나기를 기다리는 동안에도 명령어를 계속 실행할 수 있도록 하여 이런 지연을 일부 감출 수 있다.

2. Can't always schedule around branches(Branch outcome is dynamically determined)
만약 프로세서가 dynamic branch prediction을 사용하여 분기 결과에 대해 추정한다면 컴파일 시에는 명령어의 정확한 순서를 알 수 없다. 
이 순서는 branch에 대한 예측과 실제 branch outcome에 따라 달라지기 때문이다. dynamic scheduling을 사용하지 않고 
더 많은 ILP를 찾으려고 dynamic speculation을 하면 추정의 이득이 크게 제한될 것이다.

3. Different implementations of an ISA have different latencies and hazards
pipeline latency 와 issue width(the maximum number of instructions that can be issued during the same cycle)는 
구현마다 다르기 때문에, 코드를 잘 컴파일하는 방법도 달라진다. 
how to schedule a sequence of dependent instructions is affected by both issue width and latency 
The pipeline structure affects both the number of times a loop must be unrolled to avoid stalls
as well as the process of compiler-based register renaming.

Dynamic scheduling은 하드웨어로 하여금 이런 세부 사항의 대부분을 감추도록 해준다. 따라서 사용자나 소프트웨어 공급자가 
같은 명령어 집합의 여러가지 구현에 맞추어 한 프로그램이 여러 가지 버전을 가져야 할 것을 염려할 필요가 없다. 같은 이유로
오래된 코드도 재컴파일할 필요 없이 새로운 구현에 의해 얻어지는 대부분의 이득을 취할 수 있다.
