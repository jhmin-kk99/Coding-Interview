Pipeline이란?

단일사이클은 설계가 올바르게 작동한다 하더라도 비효율성 때문에 현대적 설계에서는 쓰이지 않는다.
단일사이클 설계에서는 클럭 사이클이 모든 명령어에 대해 같은 길이를 가져야 하기 때문이다. 클럭 사이클은
컴퓨터에서 가능한 경로 중 가장 긴 경로에 의해 결정된다. 이 최장 경로는 lw명령어라는 것이 거의 확실
한데, 이 적재 명령어는 명령어 메모리, 레지스터 파일, ALU, 데이터 메모리, 레지스터 파일의 다섯 개 기능
유닛을 차례로 사용한다. CPI값은 1이지만, 단일 사이클 구현은 클럭 사이클이 너무 길기 때문에 전체 성능
은 좋지 않다. 

파이프라이닝(pipelining)은 여러 명령어가 중첩되어 실행되는 구현 기술이다. 

파이프라이닝은 다음의 특성을 지닌다.
- piplelining doesn't help latency of single task, it helps throughput of entire workload
- pipeline rate limited by slowest pipeline stage
- multiple tasks operating simultaneously using different resources
- potential speedup = number pipe stages
- unbalanced lengths of pipe stages reduces speedup
- time to 'fill' pipeline and time to 'drain' it reduces speedup
- stall for dependences

MIPS pipeline은 명령어 처리에 5단계를 거친다
1. IF : Instruction fetch from memory(Ifetch)
2. ID : Instruction decode & register read(ID/Reg)
3. EX : Execute operation or calculate address(Exec)
4. MEM : Access memory operand(Mem)
5. WB : Write result back to register(Wr)

why pipeline?

suppose
- 100 instructions are executed
- the single cycle machine has a cycle time of 45ns
- the multicycle and pipeline machines have cycle times of 10ns
- the multicycle machine has a CPI of 3.6

# single cycle machine
45 ns/cycle * 1 CPI * 100 inst = 4500 ns
# multicycle machine
10 ns/cycle * 3.6 CPI * 100 inst = 3600 ns
# ideal pipelined machine
10 ns/cycle * (1 CPI * 100 inst + 4 cycle drain) = 1040 ns
# ideal pipelined vs single cycle speedup
4500 ns / 1040 ns = 4.33


명령어의 5단계 각각을 수행하는 동안, 각 명령어의 값, 레지스터의 값 등을 유지하기 위해서 해당 단계에서 
사용중인 값을 레지스터에 저장해야 한다. 이를 'Pipeline Register'라고 한다.

다음 명령어가 다음 클럭 사이클에 실행될 수 없는 상황이 있다. 이러한 사건을 해저드(hazard)라 부르는데 세 종류가 있다.

# structural hazards(구조적 해저드) : attempt to use the same resource two different ways at the same time
- Eg. two instructions try to read the same memory at the same time
구조적 해저드는 클럭 사이클에 실행하기를 원하는 여러 명령어들의 수행을 하드웨어가 지원할 수 없기 때문에 발생한다. 
각 파이프라인의 단계는 자신이 맡은 동작을 실행하기 위해서 메모리나 레지스터 등의 구성 요소를 사용하게 되는데, 
같은 파이프라인 단계에 있는 명렁어들이 동시에 하나의 자원을 같이 사용하려고 하면 파이프라인이 지연될 수 있다. 
파이프라인을 설계할 때 구조적 해저드를 피하도록 유의해야한다.

solution 1 : Instruction fetch would have to stall for that
- would cause a pipeline 'bubble'
solution 2 : pipelined datapaths require separate instruction/data memories
- or separate instruction/data caches
solution 3 : allow memory to read and write more than one word per cycle 
- 2 read, 1 write port가 있는 register file 처럼

# data hazards(데이터 해저드) : attempt to use item before it is ready
- instruction depends on result of prior instruction still in the pipeline
add r1, r2, r3
sub r4, r2, r1

solution 1 : insert the stalls(nops)
- this really slows us down
solution 2 : Internal bypassing, Data forwarding
Internal bypassing
- fix register file access hazard by doing reads in the second half of the cycle and writes in the first half
register file의 Read Address1 혹은 Read Address2와 Write Address가 같으면, Write Data를 Read Data1 혹은 Read Data2에 보내준다.
Data forwarding
- Use temporary results, don't wait for them to be written 

1. 
add r1,r2,r3
sub r1,r1,r5
and r6,r7,r1
or r8,r1,r1
sw r4,100(r1)
data forwarding으로 해결 가능
- can fix data hazard by forwarding results as soon as they are available to where they are needed)
2.
add $1,$1,$2
add $1,$1,$3
add $1,$1,$4
another potential data hazard can occur
- when there is a conflict between the result of the WB stage instruction and the MEM stage instruction
- which should be forwarded? More recent result!
3.
lw $2,20($1)
and $4,$2,$5
can't always avoid stalls by forwarding
- if value not computed when needed
- can't forward backward in time!
must delay/stall instruction dependent on loads

# control hazards(제어 해저드) : attempt to make a decision before condition is evaluated
- branch instructions
beq r1, r4, loop
add r1, r2, r3

branch determines flow of control
- conditional branches (beq, bne)
- unconditional branches (j)
when the flow of instruction addresses is not sequential; incurred by change of instructions(Branch)
- fetching next instruction depends on branch outcome
- pipeline can't always fetch correct instruction

solution1 : stall
- wait until decision is clear
j incur 1 stall
jumps not decoded until ID, so one flush is needed (pc+4)

solution2 : reducing branch delay 
move decision point earlier in the pipeline(from to ID stage)
1. move the branch decision hardware back to the EX stage
- reduces the number of stall (flush) cycles to two
- adds an and gate and a 2x1 mux to the EX timing path

2. add hardware to compute the branch target address and evaluate the branch decision to the ID stage
- reduces the number of stall (flush) cycles to one (like with jumps)
(but now need to add forwarding hardware in ID stage)
- computing branch target address can be done in parellel with RegFile read
(done for all instructions - only used when needed)
- comparing the registers can't be done until after RegFile read, so comparing and updating the PC adds
a mux, a comparator, and an and gate to the ID timing path

3. For deeper pipelines, branch decision points can be even later in the pipeline, incurring more stalls

solution3 : predict
longer pipelines can't readily determine branch outcome early
- stall penalty becomes unacceptable
predict outcome of branch
-only stall if prediction is wrong
in MPIS pipeline
- can predict branches not taken
- fetch instruction after branch, with no delay
- back up if wrong
(Impact : 1 clock cycle per branch instruction if right, 2 cycles if wrong)

More-Realistic Branch Prediction

Static branch prediction(정적 분기 예측)
Based on typical branch behavior
Example : loop and if-statement branches
- predict backward branches taken (Loop을 많이 돌 것으로 예측)
- predict forward branches not taken

Dynamic branch prediction(동적 분기 예측)
Hardware measures actual branch behavior
- e.g. record recent history of each branch
Assume future behavior wil continue the trend
- When wrong, stall while re-fetching, and update history

solution4 : delay decision (requires compiler support)
control hazards occur less frequently than data hazards
- there is nothing as effective against control hazards as forwarding is for data hazards

Unexpected Events in Pipeline

Exception(예외자) : Arises within the CPU
- e.g. undefined opcode, overflow, syscall ...
Interrupt : From an external I/O controller

"Unexpected" events requiring change in flow of control
(정상적으로 진행하다가 서비스루틴을 실행하기 때문에 control flow가 변경됨)
- Different ISAs use the terms differently

Dealing with them without sacrificing performance is hard

Two types of Exceptions

# Interrupts - asynchronous(비동기) to program execution
- caused by external events (별도의 이벤트, 파이프라인 계산 결과에 영향x)
- may be handled between instructions, so can let the instructions currently active in the pipeline complete
before passing control to the OS interrupt handler
- simply suspend and resume user program
새로운 명령어를 가져오는 것이 아니라 멈추고 서비스루틴에 들어간 후 끝나면 실행함

# Traps(Exception) - synchronous(동기) to program execution
- caused by internal events
- condition must be remedied by the trap handler for that instruction, so much stop the offending instruction midstream in the pipeline and pass control to the OS trap handler
(cache miss, pagefault ...)
- the offending instruction may be retried (or simulated by the OS) and the program may continue or it may be 
aborted

동기 : 동시에 일어난다는 뜻. 요청과 그 결과가 동시에 일어남. 바로 요청을 하면 시간이 얼마나 걸리던지 요청한 자리에서
결과가 주어져야함
설계가 매우 간단하고 직관적이지만, 결과가 주어질 때까지 아무것도 못하고 대기해야함

비동기 : 요청과 결과가 동시에 일어나지 않음
동기보다 복잡하지만, 결과가 주어지는데 시간이 걸리더라도 그 시간동안 다른 작업을 할 수 있으므로 자원을 효율적으로 사용가능

Exceptions are just another form of control hazard
Exceptions arise from
- R-type arithmetic overflow (stage : EX / synchronous)
- Trying to execute an undefined instruction (stage : ID / synchronous)
- An I/O device request (stages : IF, MEM / synchronous)
- An OS service request (e.g. a page fault, TLB exception) (stages : any / asynchronous)
- A hardware malfunction (stages : any / asynchronous)

The pipeline must stop executing the offending instruction in midstream
- let all prior instructions(상관없음) complete,
- flush all following instructions,
- set a register to show the cause of the exception,
- save the address of the offending instruction,
- and then jump to a prearranged address (the address of the exception handler code) (service routine 실행)
The software (OS) looks at the cause of the exception and "deals" with it

Handling Exceptions
In MIPS, exceptions managed by System Control Coprocessor(CP0)
Save PC of offending (or interrupted) instruction
- In MIPS : Exception Program Counter(EPC)
(offending instruction의 return address를 가져오기 위해(PC+4))
Save Indication of the problem
- In MIPS : Cause register
Jump to a service handler

Vectored Interrupts
- Handler address determined by the cause
Example :
- Undefined opcode : C000 0000
- Overflow : C000 0020
- ...
Instructions either
- Deal with the interrupt, or
- Jump to real handler

Handler Actions
Read cause, and transfer to relevent handler
Determine action required
If restartable (Pipeline can flush the instruction)
- Take corrective action 
- use EPC to return to program (Refetched and executed from scratch (처음부터 다시 시작))
PC saved in EPC register : 
- Identifies causing instruction
- Actually PC+4 is saved (Handler must adjust)

Otherwise(undefined instruction, hardware malfunction ...)
- Terminate program
- Report error using EPC, cause, ...

Consider overflow on add in EX stage
add $1, $2, $1
- Prevent $1 from being clobbered
- Complete previous instructions
- Flush add and subsequent instructions
- Set Cause and EPC register values
- Transfer control to handler

Additions to MIPS to Handle Exceptions
Cause register(records exceptions) 
- hardware to record in Cause the exceptions and a signal to control writes to it
(CauseWrite)
EPC register(records the addresses of the offending instructions) 
- hardware to record in EPC the address of the offending instruction and a signal to control writes to it
(EPCWrite)
A way to load the PC with the address of the exception handler
- Expand the PC input mux where the new input is hardwired to the exception handler address
-(e.g. 8000 0180hex for arithmetic overflow)
A way to flush offending instruction and the ones that follow it

Pipelining overlaps multiple instructions
- Could have multiple exceptions at once
Simple approach : deal with exception from earliest instruction
- Flush subsequent instructions
- "Precise" exceptions (Modern processors)
In complex pipelines
- Multiple instructions issued per cycle
- Out-of-order completion
- Maintaining precise exceptions is difficult!

Imprecise Exceptions
Just stop pipeline and save state
- Including exception cause(s)
Let the handler work out
- which instruction(s) had exceptions
- which to complete or flush
(may require "manual" completion)
Simplifies hardware, but more complex handler software
Not feasible for complex multiple-issue
out-of-order pipelines

Instruction-Level Parallelism (ILP) 에서 더 병렬도를 높이는 방법

# Deeper pipeline
- Less work per stage (shorter clock cycle)
세탁소 비유에서, 세탁기 사이클이 다른 것들에 비해 길다면, 세탁기를 3개의 기계로 나눌 수 있다.
한 기계가 하던 세탁, 헹굼, 탈수의 3단계를 각각 다른 기계로 나눌 수 있다. 그렇게 하면 4단계 파이프라인에서 6단계 파이프라인으로 바뀐다. 최고 성능을 얻기 위해서는 나머지 단계들을 다시 균형을 잡아서 단계들이 같은 길이를 갖도록 할 필요가 있다.
더 많은 연산들이 중첩되기 때문에 추구되는 병렬성의 양은 늘어나고, 클럭 사이클이 더 짧아질 것이기 때문에 성능이 더 좋아질 가능성이 있다.

# Multiple issue
매 파이프라인 단계에서 다수의 명령어를 내보낼 수 있도록 하는것
- Replicate pipeline stages (multiple pipelines)
- Start multiple instructions per clock cycle
- CPI < 1, so use Instructions Per Cycle (IPC)
pipeline에서 이상적인 CPI는 1이다. 매 단계마다 다수의 명령어를 내보내면 CPI가 1보다 작아질 수 있다. CPI값이 1보다 작아지면 측도를 뒤집어서 IPC 를 사용하기도 한다.
- E.g. 4GHZ 4-way multiple-issue 
(16 BIPS, peak CPI = 0.25, peak IPC = 4)
- But dependencies reduce this in practice

Static muiltiple issue (컴파일 시에, 정적으로)
- Compiler groups instructions to be issued together
- Packages them into "issue slots"
- Compiler detects and avoids hazards
static multiple issue에서 같은 클럭 사이클에 내보내지는 명령어의 묶음(issue packet)을 여러 개의 연산자를 갖는 큰 명령어 하나로 생각할 수 있다. 일반적으로 주어진 클럭 사이클에 같이 나갈 수 있는 명령어 조합에 제한이 있기 때문에, issue packet을 미리 정의된 필드에 여러 연산자가 있는 단일 명령어로 보는 것이 유용하다.
Compiler groups instructions into "issue packets"
- Group of instructions that can be issued on a single cycle
- Determined by pipeline resources required

Think of issue packet as a very long instruction
- Specifies multiple concurrent operations
-> Very Long Instruction Word (VLIW)




Dynamic multiple issue (실행 중에, 동적으로)
- CPU examines instruction stream and chooses instructions to issue each cycle
- Compiler can help by reordering instructions
- CPU resolves hazards using advanced techniques at runtime

이 두가지가 서로 다른 방법이라고 말하기는 하지만, 실제 기법에서는 한 방법이 다른 방법에 차용되는
경우가 많기 때문에 어느 방법도 완전히 순수하다고 말할 수는 없다.

성능 향상 방법 : Speculation (추정)
예측이라는 개념을 기반으로 하여 추정은 컴파일러나 프로세서가 명령어의 특성에 대해 추측하도록
허락하여 이 명령어에 종속적일 수 있는 다른 명령어들의 실행을 시작할 수 있게 하는 방법이다. 
- e.g. branch 명령어의 결과를 추정한다면 branch 뒤의 명령어들이 일찍 실행될 수 있다. 
- e.g. lw 명령어 바로 앞의 sw 명령어가 같은 주소를 참조하지 않는다고 추정하여, lw 명령어가
sw 명령어보다 먼저 실행될 수 있게 하는 것이다.
Start operation as soon as possible
Check whether guess was right
- if so, complete the operation
- if not, roll-back and do the right thing
어떠한 추정 기법도 추정이 올바른지를 체크할 방법과 추정해서 실행했던 명령어들을 되돌리거나 아니면
그 효과를 취소하는 방법을 포함하여야 한다. 이 같은 취소 능력에 대한 구현은 추정을 지원하는 프로세서가 더 높은 복잡도를 가지게 한다.

Compiler can reorder instructions
E.g. speculation to reorder an instruction across branch or load across store instruction.
Can include "fix-up" instructions to recover from incorrect guess
컴파일러는 추정의 정확성을 체크할 명령어들을 추가하고 추정이 잘못되었을 때 사용 할 오류 수정 루틴을 제공한다.

Hardware can look ahead for instructions to execute
Buffer results until they are determined and then actually needed
Flush buffers on incorrect speculation
하드웨어 추정인 경우 프로세서는 추정 결과가 더이상 추정이 아니라는 걸 알 때까지 추정 결과를 버퍼링하는 것이 보통이다. 추정이 옳다면 버퍼의 내용을 레지스터나 메모리에 씀으로써 명령어 실행이 완성된다. 만약 추정이 틀렸으면 하드웨어는 버퍼내용을 쓸어버리고 올바른 명령어 순서를 다시 실행한다.

What if exception occurs on a speculatively executed instruction?
e.g. speculative load before null-pointer-check

Static speculation(컴파일러 기반의 추정)
- can add ISA support for deferring exceptions
(예외가 정말 일어나야 한다는 사실이 확실해질 때까지 무시할 수 있게 해 주는 ISA support를 추가한다.)
Dynamic speculation(하드웨어 기반의 추정)
- can buffer exceptions until instruction completion(which may not occur)
(예외를 버퍼링해 두었다가, 예외를 일으킨 명령어가 추정 상태에서 벗어나 실행완료할 준비가 되면 이때 예외를 일으키고 정상적인 예외처리를 진행한다.)

추정이 올바르게 이루어지면 성능이 향상되고 추정이 잘못되면 성능이 감소하기 때문에 추정을 언제 하는 것이 좋은지 결정하는 데 막대한 노력을 기울여야 한다. 













